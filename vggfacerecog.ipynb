{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img):\n",
    "    faces = detect_faces(img)\n",
    "    if faces:\n",
    "        face_features = face_recognition.face_encodings(img, faces)\n",
    "        return face_features[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to detect faces in an image using face_recognition\n",
    "def detect_faces(img):\n",
    "    return face_recognition.face_locations(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhammad Mehdi\\OneDrive - University of Engineering and Technology Taxila\\UET, Taxila\\Semester 8\\Final Year Project -II (FYP-2)\\Face Recogntion\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhammad Mehdi\\OneDrive - University of Engineering and Technology Taxila\\UET, Taxila\\Semester 8\\Final Year Project -II (FYP-2)\\Face Recogntion\\Images\n",
      "c:\\Users\\Muhammad Mehdi\\OneDrive - University of Engineering and Technology Taxila\\UET, Taxila\\Semester 8\\Final Year Project -II (FYP-2)\\Face Recogntion\\Images\\167A1160-2.jpg\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Read all images and extract features\n",
    "folder_name = 'Images'\n",
    "image_dir = f\"{cwd}\\{folder_name}\"  # Replace with the path to your images directory\n",
    "print(image_dir)\n",
    "images = []\n",
    "features = []\n",
    "for file in os.listdir(image_dir):\n",
    "    img_path = os.path.join(image_dir, file)\n",
    "    print(img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "    faces = detect_faces(img)\n",
    "    for face_location in faces:\n",
    "        top, right, bottom, left = face_location\n",
    "        face = img[top:bottom, left:right]\n",
    "        face_features = extract_features(face)\n",
    "        if face_features:\n",
    "            features.append(face_features[0])\n",
    "            images.append((file, face_location))\n",
    "\n",
    "# Convert features to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster faces using face_recognition's compare_faces\n",
    "# Instead of clustering, we will use face_recognition's compare_faces to find matches\n",
    "unique_labels = []\n",
    "labeled_images = {}\n",
    "label_counter = 0\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    match = False\n",
    "    for label in unique_labels:\n",
    "        if face_recognition.compare_faces([label], feature, tolerance=0.6)[0]:\n",
    "            if label_counter not in labeled_images:\n",
    "                labeled_images[label_counter] = []  # Initialize list if key doesn't exist\n",
    "            labeled_images[label_counter].append(images[i])\n",
    "            match = True\n",
    "            break\n",
    "    if not match:\n",
    "        unique_labels.append(feature)\n",
    "        labeled_images[label_counter] = [images[i]]\n",
    "        label_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save labeled images information\n",
    "with open('labeled_images.pkl', 'wb') as f:\n",
    "    pickle.dump(labeled_images, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Function to find matches in provided image\n",
    "def find_matches(query_image_path):\n",
    "    # Read query image and detect faces\n",
    "    query_image = cv2.imread(query_image_path)\n",
    "    query_faces = detect_faces(query_image)\n",
    "    \n",
    "    # Iterate over each detected face in the query image\n",
    "    for face_location in query_faces:\n",
    "        top, right, bottom, left = face_location\n",
    "        query_face = query_image[top:bottom, left:right]\n",
    "        query_face_features = extract_features(query_face)\n",
    "        \n",
    "        # Compare the query face with stored face encodings\n",
    "        if query_face_features:\n",
    "            query_face_feature = query_face_features[0]\n",
    "            for label, image_data in labeled_images.items():\n",
    "                label_encoding = label\n",
    "                for (file, bbox) in image_data:\n",
    "                    img = cv2.imread(os.path.join(image_dir, file))\n",
    "                    top, right, bottom, left = bbox\n",
    "                    face = img[top:bottom, left:right]\n",
    "                    face_features = extract_features(face)\n",
    "                    if face_features:\n",
    "                        face_feature = face_features[0]\n",
    "                        # Compare the face features\n",
    "                        if face_recognition.compare_faces([label_encoding], query_face_feature, tolerance=0.6)[0]:\n",
    "                            # Display the image with annotated bounding box\n",
    "                            cv2.rectangle(img, (left, top), (right, bottom), (255, 0, 0), 2)\n",
    "                            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                            plt.show()\n",
    "\n",
    "# Provide the path to the query image\n",
    "query_image_path = 'img1.jpg'\n",
    "find_matches(query_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
