{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing images\n",
    "folder_path = \"Images/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m rgb_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(resized_image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Find face locations and encodings in the image\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m face_locations \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcnn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m face_encodings \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_encodings(rgb_image, face_locations)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Assign labels to faces based on their encodings\u001b[39;00m\n",
      "File \u001b[1;32mq:\\Python 3.10.5 (64-bit)\\lib\\site-packages\\face_recognition\\api.py:119\u001b[0m, in \u001b[0;36mface_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03mReturns an array of bounding boxes of human faces in a image\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m:return: A list of tuples of found face locations in css (top, right, bottom, left) order\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face\u001b[38;5;241m.\u001b[39mrect), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_raw_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcnn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m _raw_face_locations(img, number_of_times_to_upsample, model)]\n",
      "File \u001b[1;32mq:\\Python 3.10.5 (64-bit)\\lib\\site-packages\\face_recognition\\api.py:103\u001b[0m, in \u001b[0;36m_raw_face_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03mReturns an array of bounding boxes of human faces in a image\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m:return: A list of dlib 'rect' objects of found face locations\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcnn_face_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m face_detector(img, number_of_times_to_upsample)\n",
      "\u001b[1;31mMemoryError\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "# Initialize variables to store encodings and labels\n",
    "known_encodings = []\n",
    "known_labels = []\n",
    "label_count = 0\n",
    "\n",
    "# Set the minimum confidence value for face matching\n",
    "min_confidence = 0.6  # Adjust this value as needed\n",
    "\n",
    "# Resize parameters\n",
    "resize_factor = 0.5  # Adjust this factor to resize images\n",
    "\n",
    "# Iterate over each image file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Resize the image to reduce memory usage\n",
    "        resized_image = cv2.resize(image, (0, 0), fx=resize_factor, fy=resize_factor)\n",
    "        \n",
    "        # Convert the resized image from BGR to RGB (face_recognition uses RGB)\n",
    "        rgb_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Find face locations and encodings in the image\n",
    "        face_locations = face_recognition.face_locations(rgb_image, model=\"cnn\")\n",
    "        face_encodings = face_recognition.face_encodings(rgb_image, face_locations)\n",
    "        \n",
    "        # Assign labels to faces based on their encodings\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Calculate the confidence level of the face detection\n",
    "            confidence = (right - left) * (bottom - top) / (rgb_image.shape[0] * rgb_image.shape[1])\n",
    "            \n",
    "            # Check if the confidence level meets the minimum threshold\n",
    "            if confidence >= min_confidence:\n",
    "                # Initialize flag to check if a face has been assigned a label\n",
    "                face_assigned = False\n",
    "                \n",
    "                # Compare the encoding with known encodings\n",
    "                for i, known_encoding in enumerate(known_encodings):\n",
    "                    # Compare the face encoding with known encodings\n",
    "                    distance = face_recognition.face_distance([known_encoding], face_encoding)\n",
    "                    \n",
    "                    # Check if the distance is within the confidence threshold\n",
    "                    if distance < min_confidence:\n",
    "                        # If a match is found, assign the corresponding label\n",
    "                        face_assigned = True\n",
    "                        label = known_labels[i]\n",
    "                        break\n",
    "                \n",
    "                # If face is not assigned a label, assign a new unique label\n",
    "                if not face_assigned:\n",
    "                    label_count += 1\n",
    "                    label = label_count\n",
    "                    \n",
    "                    # Store the encoding and label\n",
    "                    known_encodings.append(face_encoding)\n",
    "                    known_labels.append(label)\n",
    "                    \n",
    "                # Draw rectangle around the face and annotate with label\n",
    "                # Scale back the face locations to match original image size\n",
    "                scaled_top = int(top / resize_factor)\n",
    "                scaled_right = int(right / resize_factor)\n",
    "                scaled_bottom = int(bottom / resize_factor)\n",
    "                scaled_left = int(left / resize_factor)\n",
    "                \n",
    "                cv2.rectangle(image, (scaled_left, scaled_top), (scaled_right, scaled_bottom), (0, 255, 0), 2)\n",
    "                cv2.putText(image, f\"Face {label}\", (scaled_left, scaled_top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Save the annotated image\n",
    "        annotated_image_path = os.path.join(\"annotated_images\", filename)\n",
    "        cv2.imwrite(annotated_image_path, image)\n",
    "\n",
    "# Save the labels and corresponding image filenames\n",
    "with open(\"labels.txt\", \"w\") as file:\n",
    "    for filename, label in zip(os.listdir(folder_path), known_labels):\n",
    "        file.write(f\"{filename}: {label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
